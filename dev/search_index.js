var documenterSearchIndex = {"docs":
[{"location":"#MCVI","page":"MCVI","title":"MCVI","text":"","category":"section"},{"location":"","page":"MCVI","title":"MCVI","text":"(Image: CI) (Image: codecov.io)","category":"page"},{"location":"","page":"MCVI","title":"MCVI","text":"The Monte Carlo Value Iteration (MCVI) offline solver for POMDPs.jl.","category":"page"},{"location":"","page":"MCVI","title":"MCVI","text":"Described in","category":"page"},{"location":"","page":"MCVI","title":"MCVI","text":"Bai, H., Hsu, D., & Lee, W. S. (2014). Integrated perception and planning in the continuous space: A POMDP approach. The International Journal of Robotics Research, 33(9), 1288-1302.","category":"page"},{"location":"#Installation","page":"MCVI","title":"Installation","text":"","category":"section"},{"location":"","page":"MCVI","title":"MCVI","text":"using Pkg\nPkg.add(\"MCVI\")","category":"page"},{"location":"#Example","page":"MCVI","title":"Example","text":"","category":"section"},{"location":"","page":"MCVI","title":"MCVI","text":"using POMDPs\nusing POMDPModels\nusing MCVI\nusing Random\n\nmutable struct LightDark1DLowerBound\n    rng::AbstractRNG\nend\n\nmutable struct LightDark1DUpperBound\n    rng::AbstractRNG\nend\n\nfunction MCVI.init_lower_action(p::LightDark1D)\n    return 0\nend\n\nfunction MCVI.lower_bound(lb::LightDark1DLowerBound, p::LightDark1D, s::LightDark1DState)\n    r = @gen(:r)(p, s, MCVI.init_lower_action(p), lb.rng)\n    return r * discount(p)\nend\n\nfunction MCVI.upper_bound(ub::LightDark1DUpperBound, p::LightDark1D, s::LightDark1DState)\n    steps = abs(s.y)/p.step_size + 1\n    return p.correct_r*(discount(p)^steps)\nend\n\nprob = LightDark1D()\nsim = MCVISimulator(rng=MersenneTwister(1))\n\nsolver = MCVISolver(sim, nothing, 1, 100, 8, 500, 1000, 5000, 50, LightDark1DLowerBound(sim.rng), LightDark1DUpperBound(sim.rng))\n\nprintln(\"Solving...\")\npolicy = solve(solver, prob)\nprintln(\"Solved!\")\n\nup = updater(policy)\nreward = simulate(MCVISimulator(rng=MersenneTwister(1)), prob, policy, up, up.root)\nprintln(\"Reward: \", reward)\n\n# output\nSolving...\nGap closed!\nSolved!\nReward: 5.314410000000001","category":"page"},{"location":"#Documentation","page":"MCVI","title":"Documentation","text":"","category":"section"},{"location":"","page":"MCVI","title":"MCVI","text":"MCVISolver","category":"page"},{"location":"#MCVI.MCVISolver","page":"MCVI","title":"MCVI.MCVISolver","text":"MCVISolver <: POMDPs.Solver\n\nThe MCVI solver is a solver for POMDPs that uses Monte Carlo Value Iteration to solve the problem.      Described in Bai, H., Hsu, D., & Lee, W. S. (2014). Integrated perception and planning in the continuous space: A POMDP approach. The International Journal of Robotics Research, 33(9), 1288-1302.\n\nFields\n\nsimulater::POMDPs.Simulator\nroot::Union{BeliefNode, Nothing}\nn_iter::Int64: Number of iterations\nnum_particles::Int64: Number of belief particles to be used\nobs_branch::Int64: Branching factor (previous default: 8)\nnum_state::Int64: Number of states to sample from belief (previous default: 500)\nnum_prune_obs::Int64: Number of times to sample observation while pruning alpha edges (previous default: 1000)\nnum_eval_belief::Int64: Number of times to simulate while evaluating belief (previous default: 5000)\nnum_obs::Int64: Number of observations to sample while evaluating belief (previous default: 50)\nlbound::Any: An object representing the lower bound. The function MCVI.lower_bound(lbound, problem, s) will be called to get the lower bound for the state s - this function needs to be implemented for the solver to work.\nubound::Any: An object representing the upper bound. The function MCVI.upper_bound(ubound, problem, s) will be called to get the lower bound for the state s - this function needs to be implemented for the solver to work.\n\nReference the docs for an example of bounds implemented for the Light Dark problem.\n\n\n\n\n\n","category":"type"}]
}
